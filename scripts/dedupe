#!/usr/bin/env python

import os
import argparse
from re import compile

TITLE_REGEX = compile("\s+<title>(.*)<\/title>$")
END_REGEX = compile("\s+<\/page>$")
TITLES = set()


def main():
    """Run the main program"""

    desc = """\
Remove duplicate titles from a wikimedia dump.

This script will scan through a wikimeda dump. Any duplicate titles will be
skipped. This script creates a temporary file and then replaces the original
file.

Beware that the temporary file is roughly the same size as the original, so
make sure you have enough space on the device to temporary duplicate the file.
"""

    parser = argparse.ArgumentParser(
        description=desc, formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument(
        "input", metavar="<intput file>", help="the input file to parse"
    )

    args = parser.parse_args()

    tmp_file = args.input + ".tmp"
    # Signal whether the title should be skipped
    skip = False
    try:
        output = open(tmp_file, "w")
        with open(args.input) as _file:
            for line in _file:
                if skip:
                    if END_REGEX.match(line):
                        skip = False
                    continue
                match = TITLE_REGEX.match(line)
                if match:
                    title = match.group(1)
                    if title in TITLES:
                        print("Duplicate title: " + title)
                        skip = True
                        continue
                    TITLES.add(title)
                output.write(line)
        # Replace the old file with the deduped file
        os.rename(tmp_file, args.input)

    finally:
        # Cleanup if necessary
        if os.path.exists(tmp_file):
            os.remove(tmp_file)

main()
